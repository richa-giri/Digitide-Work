{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXEoQORxDeMWL13QsnnEM4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/richa-giri/Digitide-Work/blob/main/GenAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spiPpb-UWaRP",
        "outputId": "d480e226-d613-49d1-d6ca-dd881b601a4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.99.6)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = getpass(\"Paste your Hugging Face API key: \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85sEKZwKXSYw",
        "outputId": "2b8925c0-1e08-4ded-d2cf-5b1ab8e61a62"
      },
      "execution_count": 8,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste your Hugging Face API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load a small, public model\n",
        "generator = pipeline(\n",
        "    \"text-generation\",\n",
        "    model=\"gpt2\"\n",
        ")\n",
        "\n",
        "# Run the prompt\n",
        "result = generator(\"Explain how rainbows are formed\", max_length=100, num_return_sequences=1)\n",
        "\n",
        "# Print output\n",
        "print(result[0]['generated_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMAXJgFaYR1V",
        "outputId": "4d273d1b-8951-4f3c-b59a-a2d54d68d818"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=100) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Explain how rainbows are formed.\n",
            "\n",
            "When you do that, you will see that the black and white part of the rainbow actually appears to be a mirror.\n",
            "\n",
            "But it's not just the one part of the rainbow that shows up in a mirror.\n",
            "\n",
            "It also shows up in the form of a circle.\n",
            "\n",
            "So, it's a mirror.\n",
            "\n",
            "How can rainbows be formed?\n",
            "\n",
            "In the beginning of the book, you will see that the rainbows are not an illusion.\n",
            "\n",
            "They are actually part of the world.\n",
            "\n",
            "They are also part of the world.\n",
            "\n",
            "So, the rainbows are part of that world.\n",
            "\n",
            "And so all the rainbows that you see in the book will be part of that world.\n",
            "\n",
            "When you read the book, you will see all the rainbows that are part of the world.\n",
            "\n",
            "You will see all the rainbows that are part of the world.\n",
            "\n",
            "And you will see all the rainbows that are part of the world.\n",
            "\n",
            "And you will see all the rainbows that are part of the world.\n",
            "\n",
            "And you will see all the rainbows that are part of the world.\n",
            "\n",
            "And you will see all the rainbows that are part of\n"
          ]
        }
      ]
    }
  ]
}
